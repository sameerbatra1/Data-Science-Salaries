---
title: "R Notebook"
output:
  html_document:
    df_print: paged
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r include=TRUE, echo=TRUE, results='markup'}
library(dplyr)
library(ggplot2)

```

```{r include=TRUE, results='markup', echo=TRUE}
salaries = read.csv("data_science_salaries.csv")
sum(is.na(salaries))
colSums(is.na(salaries))
rowSums(is.na(salaries))
salaries[!complete.cases(salaries), ] 

# Display first few rows
head(salaries)
```

```{r include=True, echo=TRUE, results='markup'}
str(salaries)
```

```{r include=True, echo=False, results='markup'}
summary(salaries)
```

```{r include=TRUE, echo=TRUE, results='markup'}
# Create the grouped dataframe
country_counts <- as.data.frame(table(salaries$employee_residence))
colnames(country_counts) <- c("Country", "Frequency")

# Arrange by Frequency in ascending order
country_counts <- country_counts[order(country_counts$Frequency, decreasing = TRUE), ]

# View the result
country_counts

# Create the barplot
ggplot(country_counts, aes(x = reorder(Country, -Frequency), y = Frequency)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(title = "Frequency of Employee Residence by Country",
       x = "Country",
       y = "Frequency") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r include=TRUE, echo=TRUE, results='markup'}
us_residents_df <- subset(salaries, employee_residence == "United States")

#Since we are only working with us_residents dataframe we need to delete salary, salary_currency
us_residents_df <- subset(us_residents_df, select= -c(employee_residence, salary, salary_currency))

us_residents_df
```

###Detecting Outliers Using IQR (Boxplot Method)
```{r include=TRUE, echo=TRUE, results='markup'}
# Function to find outliers using IQR and return entire rows
find_outliers <- function(data, column_name) {
  column <- data[[column_name]]
  Q1 <- quantile(column, 0.25, na.rm = TRUE)
  Q3 <- quantile(column, 0.75, na.rm = TRUE)
  IQR <- Q3 - Q1
  
  # Define lower and upper bounds
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  
  # Identify outliers (rows where the value is outside the bounds)
  outliers <- data[column < lower_bound | column > upper_bound, ]
  return(outliers)
}

# Apply function to salary and salary_in_usd
outliers_salary_usd <- find_outliers(us_residents_df, "salary_in_usd")
outliers_salary_usd
# Display the outliers
#list(Salary_Outliers = outliers_salary, Salary_USD_Outliers = outliers_salary_usd)

```

###Visualizing Outliers with Boxplots
```{r include=TRUE, echo=TRUE, results='markup'}


# Boxplot for Salary in USD
ggplot(us_residents_df, aes(y = salary_in_usd)) +
  geom_boxplot(fill = "lightblue", outlier.color = "red") +
  labs(title = "Boxplot of Salary in USD", y = "Salary in USD")
```

```{r include=TRUE, echo=TRUE, results='markup'}
outliers_salary_usd
```

```{r include=TRUE, echo=FALSE, results='markup'}
# Get the indices of the rows with outliers in salary and salary_in_usd
outlier_rows_salary_usd <- which(us_residents_df$salary_in_usd %in% outliers_salary_usd$salary_in_usd)

# Remove outliers from the original dataset using subset
cleaned_salaries <- us_residents_df[-outlier_rows_salary_usd, ]
cleaned_salaries
```

```{r include=TRUE, echo=TRUE, results='markup'}
## Get the indices of the rows with outliers in salary and salary_in_usd
#outlier_rows_salary <- which(salaries$salary %in% outliers_salary$salary)
#outlier_rows_salary_usd <- which(salaries$salary_in_usd %in% outliers_salary_usd$salary_in_usd)

# Combine the indices of both outliers
#outlier_rows <- unique(c(outlier_rows_salary, outlier_rows_salary_usd))

# Remove outliers from the original dataset using subset
#cleaned_salaries <- salaries[-outlier_rows, ]
```

```{r include=TRUE, echo=TRUE, results='markup'}
cleaned_salaries
```
After removing the outliers, there are 5204 values in the dataframe. This means that 101 values were outliers.


```{r include=TRUE, echo=TRUE, results='markup'}
ggplot(cleaned_salaries, aes(y = salary_in_usd)) +
  geom_boxplot(fill = "lightblue", outlier.color = "red") +
  labs(title = "Boxplot of Salary in usd", y = "Salary")
```


```{r include=TRUE, echo=TRUE, results='markup'}
# Count occurrences of each job_title
#job_title_counts <- table(cleaned_salaries$job_title)
#job_title_counts
# Find job titles that occur more than or equal to 10 times
#valid_job_titles <- names(job_title_counts[job_title_counts >= 10])

# Filter the dataframe to only include these job titles
#filtered_salaries <- subset(cleaned_salaries, job_title %in% valid_job_titles)

# Display the filtered dataframe
#subset(filtered_salaries$job_title == "Other")
```


###1. How do salaries vary across different experience levels in data science?
```{r include=TRUE, echo=TRUE, results='markup'}
# Step 1: Calculate the frequencies of each job title
job_title_freq <- table(cleaned_salaries$job_title)

# Step 2: Create the histogram of job title frequencies
# Convert the frequency table into a data frame for plotting
job_title_freq_df <- as.data.frame(job_title_freq)

# Plotting the histogram
library(ggplot2)

ggplot(freq_df, aes(x = reorder(job_title, -frequency), y = frequency)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +  # Bar plot for categorical data
  labs(
    title = "Job Title Frequencies",  # Plot title
    x = "Job Title",  # X-axis label
    y = "Frequency"   # Y-axis label
  ) +
  theme_minimal() +  # Minimal theme
  theme(axis.text.x = element_text(angle = 90, hjust = 1))  # Rotate x-axis labels for readability`
```

### 2. What is the average salary difference between remote and in-person data science jobs?
```{r include=TRUE, echo=TRUE, results='markup'}

# Check column names to verify correct variable name
colnames(cleaned_salaries)

# Convert work_models to a factor (important for t-test)
cleaned_salaries$work_models <- as.factor(cleaned_salaries$work_models)

# Compute average salary by work model
work_model_salary <- cleaned_salaries %>%
  group_by(work_models) %>%
  summarise(
    Avg_Salary_USD = mean(salary_in_usd, na.rm = TRUE),
    Count = n()
  )

# Display results
print(work_model_salary)

# Perform t-test to check if salary difference is significant
if (length(unique(cleaned_salaries$work_models)) == 2) {  # Ensure exactly two categories exist
  t_test_result <- t.test(salary_in_usd ~ work_models, data = cleaned_salaries, na.action = na.omit)
  print(t_test_result)
} else {
  print("T-test cannot be performed: work_models column does not have exactly two groups.")
}

# Boxplot of Salary by Work Model
ggplot(cleaned_salaries, aes(x = work_models, y = salary_in_usd, fill = work_models)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Salary Comparison: Remote vs. In-Person", x = "Work Model", y = "Salary in USD")

```

### 3. How have salary trends in data science evolved from 2020 to 2024?
```{r include=TRUE, echo=TRUE, results='markup'}

# Compute average salary by year
salary_trends <- cleaned_salaries %>%
  group_by(work_year) %>%
  summarise(
    Avg_Salary_USD = mean(salary_in_usd, na.rm = TRUE),
    Count = n()
  )

# Display results
print(salary_trends)

# Line plot for Salary Trends
ggplot(salary_trends, aes(x = work_year, y = Avg_Salary_USD)) +
  geom_line(color = "blue", size = 1) +
  geom_point(color = "red", size = 2) +
  theme_minimal() +
  labs(title = "Salary Trends in Data Science (2020-2024)", x = "Year", y = "Average Salary in USD")

```

# 4. Difference in salaries with respect to company size
```{r include=TRUE, echo=TRUE, results='markup'}
library("scales")
salary_summary <- cleaned_salaries %>%
  group_by(company_size) %>%
  summarise(
    mean_salary = mean(salary_in_usd, na.rm = TRUE),
    median_salary = median(salary_in_usd, na.rm = TRUE),
    count = n()
  )

print(salary_summary)


#visualization
ggplot(cleaned_salaries, aes(x = company_size, y = salary_in_usd, fill = company_size)) +
  geom_boxplot() +
  labs(title = "Salary Distribution by Company Size", x = "Company Size", y = "Salary (USD)") +
  scale_y_continuous(labels = comma)
  theme_minimal()

#ANOVA Test
anova_result <- aov(salary_in_usd ~ company_size, data = cleaned_salaries)
summary(anova_result)

# Post-hoc analysis using Tukey's test
tukey_result <- TukeyHSD(anova_result)
print(tukey_result)

```

#5. Which job title earned the most in 2024?
```{r include=TRUE, echo=TRUE, results='markup'}

salaries_2024 <- cleaned_salaries %>%
  filter(work_year == 2024)

# average salaries by job title
top_job <- salaries_2024 %>%
  group_by(job_title) %>%
  summarise(
    mean_salary = mean(salary_in_usd, na.rm = TRUE),
    max_salary = max(salary_in_usd, na.rm = TRUE),
    count = n()
  ) %>%
  arrange(desc(mean_salary))
print(top_job)

#top 10
top_10_jobs <- top_job %>% head(10)

ggplot(top_10_jobs, aes(x = reorder(job_title, mean_salary), y = mean_salary, fill = job_title)) +
  geom_bar(stat = "identity") +
  coord_flip() +  
  labs(title = "Top 10 Highest Paying Job Titles in 2024", x = "Job Title", y = "Average Salary (USD)") +
  scale_y_continuous(labels = comma)
 ` theme_minimal()


highest_paid_job <- salaries_2024 %>%
  filter(salary_in_usd == max(salary_in_usd, na.rm = TRUE))
print(highest_paid_job)
```

```{r include=TRUE, echo=TRUE, results='markup'}
ggplot(cleaned_salaries, aes(x = work_year, y = salary_in_usd)) +
  geom_line()
```

# Step 1: Calculate the frequencies of each job title
job_title_freq <- table(cleaned_salaries$job_title)

# Step 2: Create the frequency table as a data frame for plotting
job_title_freq_df <- as.data.frame(job_title_freq)

# Plotting the histogram
library(ggplot2)

ggplot(job_title_freq_df, aes(x = reorder(job_title, -Freq), y = Freq)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +  # Bar plot for categorical data
  labs(
    title = "Job Title Frequencies",  # Plot title
    x = "Job Title",  # X-axis label
    y = "Frequency"   # Y-axis label
  ) +
  theme_minimal() +  # Minimal theme
  theme(axis.text.x = element_text(angle = 90, hjust = 1))  # Rotate x-axis labels for readability

```

Since this representation does not seem right we need to group the job_title categories that are less than 20 into other category and then convert the frequencies into logarthmic scale for better representation.

```{r include=TRUE, echo=TRUE, results='markup'}

freq_table <- table(cleaned_salaries$job_title)

freq_df <- as.data.frame(freq_table, stringsAsFactors = FALSE)

colnames(freq_df) <- c("job_title", "frequency")


threshold <- 20

freq_df$job_title[freq_df$frequency <= threshold] <- "Other"


freq_df <- aggregate(frequency ~ job_title, data = freq_df, sum)


freq_df <- freq_df[order(-freq_df$frequency), ]


cleaned_salaries$job_title <- ifelse(
  cleaned_salaries$job_title %in% valid_job_titles,
  cleaned_salaries$job_title, 
  "Other"                     
)


cleaned_salaries
```

Rather than keeping job titles that appeared less than 20 times as separate titles, we aggregated them into "other" keyword.


```{r include=TRUE, echo=TRUE, results='markup'}
freq_df
```

```{r include=TRUE, echo=TRUE, results='markup'}
ggplot(freq_df, aes(x = reorder(job_title, -frequency), y = frequency)) +
  geom_bar(stat = "identity", fill = "skyblue") +  # Bar plot
  labs(
    title = "Job Title Frequencies",  # Plot title
    x = "Job Title",  # X-axis label
    y = "Frequency"   # Y-axis label
  ) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))  # Rotate x-axis labels
```

The above graph shows that job titles are right skewed.

```{r include=TRUE, echo=TRUE, results='markup'}
freq_df
```

```{r include=TRUE, echo=TRUE, results='markup'}
cleaned_salaries
unique(cleaned_salaries$employment_type)
```


```{r include=TRUE, echo=TRUE, results='markup'}
threshold <- 20
# Compute frequencies and group low-frequency jobs into "Other"
binned_data <- cleaned_salaries %>%
  count(job_title, name = "frequency") %>%  # Calculate frequencies
  mutate(
    job_title = ifelse(frequency < threshold, "Other", job_title)
  ) %>%
  group_by(job_title) %>%
  summarise(frequency = sum(frequency)) %>%
  arrange(desc(frequency))

ggplot(binned_data, aes(x = reorder(job_title, -frequency), y = frequency)) +
  geom_bar(stat = "identity") +
  scale_y_log10() +  # Log scale for better visibility
  labs(title = "Job Title Frequencies", x = "Job Title", y = "Frequency (log10)") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```


```{r include=TRUE, echo=TRUE, results='markup'}
str(cleaned_salaries)
```

# Hyportheis Testing
## Shapiro-Wilk test
```{r include=TRUE, echo=TRUE, results='markup'}
set.seed(123)
# Subset the data into Full-time and Part-time groups
full_time_data <- cleaned_salaries[cleaned_salaries$employment_type == "Full-time", ]
# using only 5000 because shapiro only accepts sample size between 3 to 5000
full_time_sample <- full_time_data[sample(nrow(full_time_data), 5000), ]
part_time_data <- cleaned_salaries[cleaned_salaries$employment_type == "Part-time", ]
contract_data <- cleaned_salaries[cleaned_salaries$employment_type=="Contract", ]

# Conduct the Shapiro-Wilk test for Full-time salaries
shapiro_test_full_time <- shapiro.test(full_time_sample$salary_in_usd)
print(shapiro_test_full_time)

# Conduct the Shapiro-Wilk test for Part-time salaries
shapiro_test_part_time <- shapiro.test(part_time_data$salary_in_usd)
print(shapiro_test_part_time)

shapiro.test(contract_data$salary_in_usd)
```

Null Hypothesis: The salary data for Full-time employees is normally distributed.
Alternate Hypothesis: The salary data for Full-time employees is not normally distributed.
Results: Since the p-value is less than 2.2e-16, which is far smaller than the significance level (α = 0.05), we reject the null hypothesis. This suggests that there is enough evidence to conclude that the salary data for Full-time employees is not normally distributed.

Null Hypothesis: The salary data for Part-time employees is normally distributed.
Alternate Hypothesis: Part-time salary data does not significantly deviate from normality, meaning it is more likely to be normally distributed.
Results: Since the p-value is 0.4491, which is greater than the significance level (α = 0.05), we fail to reject the null hypothesis. This suggests that there is insufficient evidence to conclude that the salary data for Part-time employees is not normally distributed.

Null Hypothesis: The salary data for Contract employees is normally distributed.
Alternate Hypothesis: The salary data for Contract employees is not normally distributed.
Results: Since the p-value is 0.1172, which is greater than the significance level (α = 0.05), we fail to reject the null hypothesis. This suggests that there is insufficient evidence to conclude that the salary data for Contract employees is not normally distributed.

```{r include=TRUE, echo=TRUE, results='markup'}
data_manager <- cleaned_salaries[cleaned_salaries$job_title == "Data Manager", ]
shapiro.test(data_manager$salary_in_usd)

research_analyst <- cleaned_salaries[cleaned_salaries$job_title == "Research Analyst", ]
shapiro.test(research_analyst$salary_in_usd)

data_engineer <- cleaned_salaries[cleaned_salaries$job_title == "Data Engineer", ]
shapiro.test(data_engineer$salary_in_usd)

data_scientist <- cleaned_salaries[cleaned_salaries$job_title == "Data Scientist", ]
shapiro.test(data_scientist$salary_in_usd)

data_analyst <- cleaned_salaries[cleaned_salaries$job_title == "Data Analyst", ]
shapiro.test(data_analyst$salary_in_usd)

analytics_engineer <- cleaned_salaries[cleaned_salaries$job_title == "Analytics Engineer", ]
shapiro.test(analytics_engineer$salary_in_usd)
```
Null Hypothesis: The salary data for Data Manager is normally distributed.
Alternate hypothesis: The salary data for Data Manager is not normally distributed.
results: Since the p-value (0.1905) is greater than the significance level (α = 0.05), we fail to reject the null hypothesis. This suggests that there is not enough evidence to conclude that the salary data for Data Manager is not normally distributed. Therefore, we can assume that the data follows a normal distribution.

Null Hypothesis: The salary data for research analyst is normally distributed.
Alternate hypothesis: The salary data for research analyst is not normally distributed.
results: Since the p-value (0.0003165) is much less than the significance level (α = 0.05), we reject the null hypothesis. This indicates that there is enough evidence to conclude that the salary data for Research Analysts is not normally distributed.

Final Result: From the above results we can conclude that only "Data Manager" and "Analytics Engineer" have normal distribution

#T-test
```{r include=TRUE, echo=TRUE, results='markup'}
t_test_result <- t.test(data_manager$salary_in_usd, analytics_engineer$salary_in_usd)

# Print the t-test result
print(t_test_result)
```
Null Hypothesis: The average salaries of Data Managers and Analytics Engineers are equal.
Alternative Hypothesis: The average salaries of Data Managers and Analytics Engineers are not equal.
Results: Given that the p-value is 1.513e-08 (which is much smaller than 0.05), we reject the null hypothesis. This means that there is a statistically significant difference in the average salaries of Data Managers and Analytics Engineers, with Analytics Engineers earning more on average than Data Managers.

```{r include=TRUE, echo=TRUE, results='markup'}
#Conduct shapiro test and t-test if applicable on work models column
unique(cleaned_salaries$work_models)
```


```{r include=TRUE, echo=TRUE, results='markup'}
remote <- cleaned_salaries[cleaned_salaries$work_models == "Remote", ]
shapiro.test(remote$salary_in_usd)

on_site_salaries <- cleaned_salaries[cleaned_salaries$work_models == "On-site", ]
shapiro.test(on_site_salaries$salary_in_usd)

hybrid <- cleaned_salaries[cleaned_salaries$work_models == "Hybrid", ]
shapiro.test(hybrid$salary_in_usd)
```
Null Hypothesis: All of the work models are normally distributed
Alternate Hypothesis: None of the work models are normally distributed
Results: Since all of the p-values(7.492e-12, 2.2e-16, 0.03666) are less than 0.05 we reject the null hypothesis. None of the work models (Remote, On-site, or Hybrid) have salaries that follow a normal distribution based on the Shapiro-Wilk test results.

```{r include=TRUE, echo=TRUE, results='markup'}
cleaned_salaries
```

# Chi-Squared Test
### conducting chi-squared test between employment_type and work_models 
```{r include=TRUE, echo=TRUE, results='markup'}
table_data <- table(cleaned_salaries$employment_type, cleaned_salaries$work_models)
chisq_test <- chisq.test(table_data)
print(chisq_test)
chisq_test$expected
```
Null Hypothesis: There is no association between employment type and work model (they are independent).
Alternate Hypothesis: There is an association between employment type and work model (they are dependent).
Results: Since the p-value(6.673e-05) is less than 0.05, we reject the null hypothesis. There is a statistically significant association between employment type and work model. *However, we should be cautious about these results because, for a chi-squared test, the expected frequencies should be greater than 5. In this case, the expected counts for Hybrid: Contract, Contract:Remote, Part-time: Hybrid, Part-time: On-site, and Part-time: Remote are all less than 5, which may affect the reliability of the test.*

### conducting chi-squared test between company_size and work_models 
```{r include=TRUE, echo=TRUE, results='markup'}
table_data <- table(cleaned_salaries$company_size, cleaned_salaries$work_models)
chisq_test <- chisq.test(table_data)
print(chisq_test)
chisq_test$expected
```
Null Hypothesis: There is no association between company_size and work model (they are independent).
Alternate Hypothesis: There is an association between company_size and work model (they are dependent).
Results: Since the p-value(<2.2e-16) is less than 0.05, we reject the null hypothesis. There is a statistically significant association between company_size and work model. *However, we should be cautious about these results because, for a chi-squared test, the expected frequencies should be greater than 5. In this case, the expected counts for Hybrid: Large, small:hybrid are all less than 5, which may affect the reliability of the test.*

### conducting chi-squared test between work_models and experience level
```{r include=TRUE, echo=TRUE, results='markup'}
table_data <- table(cleaned_salaries$work_models, cleaned_salaries$experience_level)
chisq_test <- chisq.test(table_data)
print(chisq_test)
chisq_test$expected
```
Null Hypothesis: There is no association between work model and experience level (they are independent).
Alternate Hypothesis: There is an association between work model and experience level (they are dependent).
Results: Since the p-value(<2.2e-16) is less than 0.05, we reject the null hypothesis. There is a statistically significant association between work model and experience level. *However, we should be cautious about these results because, for a chi-squared test, the expected frequencies should be greater than 5. In this case, the expected counts for Hybrid: Entry-level, and Hybrid:Executive-level are all less than 5, which may affect the reliability of the test.*

### conducting chi-squared test between experience level and employement type
```{r include=TRUE, echo=TRUE, results='markup'}
table_data <- table(cleaned_salaries$experience_level, cleaned_salaries$employment_type)
chisq_test <- chisq.test(table_data)
print(chisq_test)
chisq_test$expected
```
Null Hypothesis: There is no association between experience level and employment type(they are independent).
Alternate Hypothesis: There is an association between experience level and employment type(they are dependent).
Results: Since the p-value(3.076e-09) is less than 0.05, we reject the null hypothesis. There is a statistically significant association between experience level and employment type. *However, we should be cautious about these results because, for a chi-squared test, the expected frequencies should be greater than 5. In this case, the expected counts for Entry-level:contract, Executive-level:contract, Entry-level:Part-time, Executive-level and part-time, mid-level:contract, mid-level:part-time and senior-level:part-time are all less than 5, which may affect the reliability of the test.*

```{r include=TRUE, echo=TRUE, results='markup'}

```


```{r include=TRUE, echo=TRUE, results='markup'}

```
